<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="icon" type="image/png" href="pic/logo.png">
<title>Changqing Fu </title>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3KEYKBJ73R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-3KEYKBJ73R');
</script>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Changqing Fu </h1>
</div>
<table class="imgtable"><tr><td>
<img src="pic/pic.jpg" alt="Profile Pic" width="300px" height="300px" />&nbsp;</td>
<td align="left"><p><b>Research Interests</b>: I'm interested in visual generative models and a broad range of topics in deep learning. Currently I'm working on the improvement neural network architectures for better parameter/training/inference efficiency and with more effective control, with a unified geometrical framework.</p>
<p>I'm a senior-year PhD student in CEREMADE, Paris Dauphine University - PSL and Paris AI Institute (PRAIRIE), fortunately advised by <a href="https://www.ceremade.dauphine.fr/~cohen/">Laurent D Cohen</a>. Before that I was a graduate student in University at Albany advised by Yiming Ying. I recieved a Master's degree on Applied and Theoretical Mathematics in PSL University advised by <a href="https://omula.gitlab.io/">Olga Mula</a> and <a href="https://sites.google.com/site/robryd/">Robin Ryder</a>, and a Bachelor's degree from School of Mathematical Sciences in Fudan University. </p>
<p>Here are my <a href="https://prairie-institute.fr/chairs/fu-changqing/">Institutional Page</a>, <a href="pdf/CV.pdf">CV</a>, <a href="https://github.com/EvergreenTree">GitHub</a>, <a href="https://twitter.com/evergreencqfu">Twitter</a> and <a href="http://www.linkedin.com/in/cqfu-fdu">Linkedin</a>.</p>
<p><b>Email</b>: cfu-at-ceremade-dot-dauphine-dot-fr, evergreencqfu_at_gmail_dot_com</p>
</td></tr></table>
<h2>Projects</h2>
<table class="imgtable"><tr><td>
<img src="pic/conv3d.png" alt="DeepPrism" width="300px" height="124px" />&nbsp;</td>
<td align="left"><p><b>DeepPrism.</b> An unprecedented 1000x better parameter-efficient network design for generative models, by leveraging an equivariance on the channel dimension, where training and inference FLOPs are also greatly reduced. This design applies equally to attention layers and maintains generation performance for a variety of models such as VAE, StableDiffusion (LDM).</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="pic/iceberg.png" alt="Tip of the Iceberg" width="300px" height="124px" />&nbsp;</td>
<td align="left"><p><b>Tip of the Iceberg.</b> An improvement on the widely-used perceptual loss, to achieve 10x more training efficieny for generative models, by calculating non-singular symmetric features instead of activations in the path-integral along layers. </p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="pic/attention.png" alt="Unifying Activation and Attention" width="300px" height="124px" />&nbsp;</td>
<td align="left"><p><b>Unifying Activation and Attention.</b> A projective-geometric point of view to unify different operators in neural networks, under which the self-attention function intrinsically coincides with the activation-convolution layers by defining proper kernel functions. This connection does not change the form of commonly-used neural networks, can be visually confirmed, and leads to a unified view of the dynamics of neural processes. </p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="pic/conic.png" alt="Conic Linear Units" width="300px" height="124px" />&nbsp;</td>
<td align="left"><p><b>Conic Linear Units.</b> A non-pointwise activation function with unprecedented infinite-order symmetry group, which improves generation quality, and enables alignment of neural networks with different widths. Application involves more flexible Federated Learning using Optimal Transport.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="pic/conj.png" alt="Contour-Based Image Manipulation" width="300px" height="124px" />&nbsp;</td>
<td align="left"><p><b>Contour-Based Image Manipulation.</b> A robust unsupervised two-stage image manipulation model by modifying contour constraints. The use of contour constraints is inspired by the sparsity of the edited constraint, while the coarse-grained post-processing single-image GAN alleviates distortion caused by out-of-distribution inputs.</p>
</td></tr></table>
<h2>Publications</h2>
<ul>
<li><p>Changqing Fu and Laurent D. Cohen. Conic Activation Functions. In <i>Proceedings of UniReps: the Second Workshop on Unifying Representations in Neural Models</i>, NeurIPS 2024, Proceedings of Machine Learning Research, Vancouver, Canada.</p>
</li>
<li><p>Changqing Fu and Laurent D. Cohen. Conic Linear Units: Improved Model Fusion and Rotational-Symmetric Generative Model. In <i>Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 2: VISAPP</i>, Virtual and Rome, Italy. <a href="pdf/visapp.pdf">pdf</a> <a href="pdf/colu_poster.pdf">poster</a></p>
</li>
<li><p>Changqing Fu and Laurent D. Cohen. DeepPrism: Channel Convolution for Lightweight Generative Models. In <i>Proceedings of the 5th International Conference on Video, Signal and Image Processing</i>, ACM 2023, Virtual and Harbin, China. (Best Presentation Award) <a href="pdf/vsip.pdf">pdf</a> <a href="pdf/vsip_slides.pdf">slides</a></p>
</li>
<li><p>Changqing Fu and Laurent D. Cohen. Geometric Deformation on Objects: Unsupervised Image Manipulation via Conjugation. In <i>Proceedings of the 8th International Conference on Scale Space and Variational Methods in Computer Vision</i>, Lecture Notes in Computer Science, Springer 2021, Virtual Event. <a href="pdf/ssvm21.pdf">pdf</a> <a href="pdf/winterschool.pdf">slides</a></p>
</li>
</ul>
<h2>Talks</h2>
<ul>
<li><p>Poster in Workshop on Geometry-Informed Machine Learning, Mines ParisTech, July 3-4, 2024, Paris, France</p>
</li>
<li><p>Stability AI Research Program @CogX, 12-14 Sep, 2023, London, UK</p>
</li>
<li><p>Symposium on AI in Biology and Health, Institut Pasteur, July 3-4, 2023, Paris, France</p>
</li>
<li><p>Speaker in Ellis unConference, July 25 2023, Paris, France</p>
</li>
<li><p>Poster in Workshop on Optimization and Machine Learning, June 26-27 2023, Toulouse, France</p>
</li>
<li><p>General session “AI in Healthcare”, INFORMS Annual Meeting, Oct 25 2021, Virtual and CA, USA </p>
</li>
<li><p>Invited Speaker in Applied Mathematics Ph.D. Seminar, Sep 13 2021, Fudan University, Shanghai, China  </p>
</li>
<li><p>Winter School for Young Researchers, CEREMADE, Feb 28 2022, Normandy, France </p>
</li>
<li><p>Speaker in Artificial Intelligence Interdisciplinary Institutes (3IA) Workshop, Nov 2021, Toulouse, France</p>
</li>
<li><p>Young Researcher's Seminar, CEREMADE, Paris Dauphine University, June 2 2023, Feb 2 2023, Feb 28 2022, Jan 20 2022, Paris, France </p>
</li>
<li><p>International Summer Program in Economics Education, Aug 2015, Hebrew University of Jerusalem</p>
</li>
<li><p>Business Summer School, Aug 2014, University of Cambridge</p>
</li>
</ul>
<h2>Reviewer Duties</h2>
<ul>
<li><p>ICCV, ECCV, AISTATS, AAAI, ICLR, NeurIPS, CVPR</p>
</li>
</ul>
</div>
</body>
</html>
